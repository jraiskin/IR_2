{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set your user name as a case, pointing to your path to documents and tinyir.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// set your case once\n",
    "val (doc_dir: String, files_path: String) = System.getProperties().get(\"user.name\").toString match {\n",
    "    case \"Yarden-\"  => (\"../documents\", \"../\")\n",
    "    case \"Max\"  => (\"/Users/Max/Coding/ETH/Information_Retrieval_AS16/scala_practice/documents\", \"/Users/Max/Coding/ETH/Information_Retrieval_AS16/scala_practice/files/\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classpath.addPath(files_path + \"tinyir-1.1.jar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import scala.xml.XML\n",
    "import ch.ethz.dal.tinyir._\n",
    "import com.github.aztek.porterstemmer.PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scala.io.Source  // for importing txt files\n",
    "import java.io._  // for saving txt files\n",
    "// import scala.collection.mutable.HashMap  //HashMap used for counting elements in linear time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// import scala.util.Random\n",
    "import scala.collection.mutable.{Map => MutMap, HashMap => MutHashMap}\n",
    "// enables \"mutable lists\"\n",
    "// import scala.collection.mutable.ListBuffer  \n",
    "import scala.collection.mutable.{Set => MutSet}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val timeit = new util.StopWatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def token_filter(text_body: String) = {\n",
    "    processing.StopWords.filterOutSW(\n",
    "        processing.Tokenizer.tokenize(text_body.\n",
    "                                      replaceAll(\"\\\\P{L}+\", \" \"))\n",
    "    ).\n",
    "    map(x => PorterStemmer.stem(x)).filter(_.trim.nonEmpty).toList\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class xml_doc (file_path: String) {\n",
    "    def get_doc(): xml.Elem = {\n",
    "        XML.loadFile(file_path: String)\n",
    "    }    \n",
    "    \n",
    "    def text() = {\n",
    "        (get_doc() \\\\ \"DOC\" \\\\ \"TEXT\").text\n",
    "    }\n",
    "    \n",
    "    def head() = {\n",
    "        (get_doc() \\\\ \"DOC\" \\\\ \"HEAD\").text\n",
    "    }\n",
    "\n",
    "    def id() = {\n",
    "        (get_doc() \\\\ \"DOC\" \\\\ \"DOCNO\").text.trim\n",
    "    }\n",
    "    \n",
    "    def tokens() = {\n",
    "        token_filter(head() ++ text())\n",
    "    }\n",
    "    \n",
    "    def hash_tokens() = {\n",
    "        tokens().map(x => x.hashCode())\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def list_docs (path: String) = {  // : Array[java.io.File]\n",
    "        new java.io.File(path).listFiles.map(x => x.toString())\n",
    "    }\n",
    "val numPattern = \"[0-9]+\".r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val token_hash = MutHashMap[String, Int]() // token -> hash\n",
    "\n",
    "def create_hash_doc_subset(star_count: Int, end_count: Int,\n",
    "                           file_list: Array[String],\n",
    "                           token_hash_map: MutHashMap[String, Int] = token_hash) = {\n",
    "    val id_htoken = MutHashMap[Int, List[Int]]() // forward index, docID to tokens\n",
    "    val htoken_id = MutHashMap[Int, List[Int]]()  // inverse index, tokens to docID\n",
    "    val id_name = MutHashMap[Int, String]()  // inverse index, tokens to docID\n",
    "    val name_id = MutHashMap[String, Int]()  // inverse index, tokens to docID\n",
    "    var counter = star_count\n",
    "    while (counter < end_count){\n",
    "        var cur_doc = new xml_doc(file_list(counter))\n",
    "        // get token from XML, then hash, or create hashes \"on the fly\"\n",
    "        var cur_htoken = cur_doc.tokens.map(x => token_hash_map.getOrElseUpdate(x, token_hash_map.size))\n",
    "        id_htoken += counter -> cur_htoken\n",
    "        \n",
    "        // update the inverse mapping, from (hashed) tokens to docID\n",
    "        cur_htoken.distinct.foreach(\n",
    "            (token: Int) => htoken_id(token) = htoken_id.getOrElseUpdate(token, List[Int]()) ++ List(counter)\n",
    "        )\n",
    "        \n",
    "        id_name(counter) = cur_doc.id\n",
    "        name_id(cur_doc.id) = counter\n",
    "        \n",
    "        counter += 1\n",
    "        if (counter % 100 == 0) println(s\"iteration $counter\")\n",
    "    }\n",
    "    (id_htoken, htoken_id, token_hash_map, id_name, name_id)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def write_int_to_intList(data: MutHashMap[Int, List[Int]], filename: String) = {\n",
    "\n",
    "    val bw = new BufferedWriter(new FileWriter(new File(filename)))\n",
    "    val iter = data.keys.iterator\n",
    "    while(iter.hasNext){\n",
    "        var elem = iter.next()\n",
    "        var values = data(elem).toList\n",
    "//         if(values.length>0){\n",
    "            bw.write(elem+\" \"+values.mkString(\" \"))\n",
    "            bw.newLine\n",
    "//         }    \n",
    "    }   \n",
    "    bw.close()\n",
    "}\n",
    "\n",
    "def write_int_string(data: MutHashMap[Int, String], filename: String) = {\n",
    "\n",
    "    val bw = new BufferedWriter(new FileWriter(new File(filename)))\n",
    "    val iter = data.keys.iterator\n",
    "    while(iter.hasNext){\n",
    "        var elem = iter.next()\n",
    "        var values = data(elem).toList\n",
    "        if(values.length>0){\n",
    "            bw.write(elem+\" \"+values.mkString(\"\"))\n",
    "            bw.newLine\n",
    "        }    \n",
    "    }   \n",
    "    bw.close()\n",
    "}\n",
    "\n",
    "def write_string_int(data: MutHashMap[String, Int], filename: String) = {\n",
    "\n",
    "    val bw = new BufferedWriter(new FileWriter(new File(filename)))\n",
    "    val iter = data.keys.iterator\n",
    "    while(iter.hasNext){\n",
    "        var elem = iter.next()\n",
    "        bw.write(elem+\" \"+data(elem).toString)\n",
    "        bw.newLine\n",
    "    }   \n",
    "    bw.close()\n",
    "}\n",
    "\n",
    "def write_int_to_int(data: MutHashMap[Int, Int], filename: String) = {\n",
    "\n",
    "    val bw = new BufferedWriter(new FileWriter(new File(filename)))\n",
    "    val iter = data.keys.iterator\n",
    "    while(iter.hasNext){\n",
    "        var elem = iter.next()\n",
    "        var value = data(elem)\n",
    "            bw.write(elem+\" \"+value)\n",
    "            bw.newLine\n",
    "    }   \n",
    "    bw.close()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_mutmap_int_intList(path: String, mutmap: MutHashMap[Int, List[Int]]) = {\n",
    "    val lines = Source.fromFile(path).getLines.toList\n",
    "    for (line <- lines){\n",
    "        val line_split = line.split(\" \", -1).filter(_.trim.length > 0)\n",
    "        mutmap(line_split.head.toInt) = \n",
    "            line_split.tail.map(x => x.toInt).toList\n",
    "    }\n",
    "}\n",
    "\n",
    "def load_mutmap_int_string(path: String, mutmap: MutHashMap[Int, String]) = {\n",
    "    val lines = Source.fromFile(path).getLines.toList\n",
    "    for (line <- lines){\n",
    "        val line_split = line.split(\" \") // .filter(_.trim.length > 0)\n",
    "        mutmap(line_split.head.toInt) = \n",
    "            line_split.last\n",
    "    }\n",
    "}\n",
    "\n",
    "def load_mutmap_string_int(path: String, mutmap: MutHashMap[String, Int]) = {\n",
    "    val lines = Source.fromFile(path).getLines.toList\n",
    "    for (line <- lines){\n",
    "//         val line_split = line.split(\" \", -1)\n",
    "        val line_split = line.split(\" \") // .filter(_.trim.length > 0)\n",
    "        mutmap(line_split.head) = \n",
    "            line_split.last.toInt\n",
    "    }\n",
    "}\n",
    "\n",
    "def load_mutmap_int_int(path: String, mutmap: MutHashMap[Int, Int]) = {\n",
    "    val lines = Source.fromFile(path).getLines.toList\n",
    "    for (line <- lines){\n",
    "        val line_split = line.split(\" \", -1).filter(_.trim.length > 0)\n",
    "        mutmap(line_split.head.toInt) = \n",
    "            line_split.last.toInt\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val mb = 1024*1024\n",
    "val runtime = Runtime.getRuntime\n",
    "def print_memory() = {\n",
    "    println(s\"Used Memory:  \" + (runtime.totalMemory - runtime.freeMemory) / mb)\n",
    "    println(s\"Free Memory:  \" + runtime.freeMemory / mb)\n",
    "    println(s\"Total Memory: \" + runtime.totalMemory / mb)\n",
    "    println(s\"Max Memory:   \" + runtime.maxMemory / mb)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val train_list = list_docs(doc_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val PATH_id_htoken = files_path + \"id_htoken.txt\"\n",
    "val PATH_htoken_id = files_path + \"htoken_id.txt\"\n",
    "val PATH_id_name = files_path + \"id_name.txt\"\n",
    "val PATH_name_id = files_path + \"name_id.txt\"\n",
    "val PATH_token_hash = files_path + \"token_hash.txt\"\n",
    "\n",
    "val PATH_prun_htoken_collectfreq = files_path + \"prun_htoken_collectfreq.txt\"\n",
    "val PATH_prun_htoken_id = files_path + \"prun_htoken_id.txt\"\n",
    "val PATH_prun_id_htoken = files_path + \"prun_id_htoken.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Results to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// use model=\"l\" to save predictions for langauge model, i.e. t and l are required for the final submission\n",
    "// but in theory can use anything for this parameter in case you want to save mulitple predictions in the same folder\n",
    "// while trying out some different scoring and ranking approaches. \n",
    "def write_res(res: Map[String, List[String]],model: String=\"t\") = {\n",
    "    val file = new BufferedWriter(new FileWriter(new File(\"ranking-\"+model+\"-24.txt\")))\n",
    "    res.foreach{case (qId,doclist) => doclist.zipWithIndex // takes each qID, doclist pair to zip the list with an index\n",
    "                .foreach{case(name,rank) => file.write(qId+\" \"+(rank+1)+\" \"+name+\"\\n\")}} // self-explanatory\n",
    "    file.close()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// Example Use (obviously need to have computed answers first)\n",
    "write_res(answers) // saves answers term model predictions\n",
    "write_res(answers,\"l\") // saves answers as language model predictions\n",
    "write_res(answers,\"abc\") // saves answers with arbitrary name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data files and creating maps\n",
    "# # not run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "// time it\n",
    "timeit.start\n",
    "\n",
    "val (id_htoken, htoken_id, token_hash, \n",
    "     id_name, name_id) = create_hash_doc_subset(0, 100000, train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// time it\n",
    "timeit.uptonow / 60.0\n",
    "// 87.56585954758334 , in minutes with 6GB\n",
    "// 67.88821773650001 , in minutes with 7GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_memory()\n",
    "\n",
    "// Used Memory:  3981\n",
    "// Free Memory:  1814\n",
    "// Total Memory: 5796\n",
    "// Max Memory:   5796"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_int_to_intList(id_htoken, PATH_id_htoken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_int_to_intList(htoken_id, PATH_htoken_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_int_string(id_name, PATH_id_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_string_int(name_id, PATH_name_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "write_string_int(token_hash, PATH_token_hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// time it\n",
    "timeit.start\n",
    "\n",
    "val id_htoken: MutHashMap[Int, List[Int]] = MutHashMap[Int, List[Int]]()\n",
    "val htoken_id: MutHashMap[Int, List[Int]] = MutHashMap[Int, List[Int]]()\n",
    "val id_name: MutHashMap[Int, String] = MutHashMap[Int, String]()\n",
    "val token_hash: MutHashMap[String, Int] = MutHashMap[String, Int]()\n",
    "val name_id: MutHashMap[String, Int] = MutHashMap[String, Int]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "load_mutmap_int_intList(PATH_id_htoken, id_htoken)\n",
    "load_mutmap_int_intList(PATH_htoken_id, htoken_id)\n",
    "load_mutmap_int_string(PATH_id_name, id_name)\n",
    "load_mutmap_string_int(PATH_token_hash, token_hash)\n",
    "load_mutmap_string_int(PATH_name_id, name_id)\n",
    "\n",
    "// confirm load successful\n",
    "// test_load_mutmap_id_htoken == id_htoken\n",
    "// test_load_mutmap_htoken_id == htoken_id\n",
    "// test_load_mutmap_id_name == id_name\n",
    "// test_load_mutmap_token_hash == token_hash\n",
    "// test_load_mutmap_name_id == name_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// time it\n",
    "timeit.uptonow / 60.0\n",
    "// 1.4485827969833334 , in minutes\n",
    "// 1.3195113773833334 , in minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_memory()\n",
    "\n",
    "// Used Memory:  3468\n",
    "// Free Memory:  649\n",
    "// Total Memory: 4117\n",
    "// Max Memory:   5461"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prune vocabulary, collection and document frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "// htoken_id.mapValues(v => v.length).size\n",
    "// 1356183\n",
    "// htoken_id.mapValues(v => v.length).filter(_._2 > 5 - 1).size\n",
    "// 176866\n",
    "// reduction factor of ~7.67\n",
    "\n",
    "val prun_threshold = 5\n",
    "val pruned_token_set = htoken_id.mapValues(v => v.length).\n",
    "    filter(_._2 > prun_threshold - 1).keys.toSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "// time it\n",
    "timeit.start\n",
    "\n",
    "val prun_htoken_collectfreq: MutHashMap[Int, Int] = \n",
    "    MutHashMap(\n",
    "        id_htoken.flatMap{ case (k,v) => v.filter(pruned_token_set.contains(_)) }.\n",
    "        groupBy(identity).mapValues(_.size)\n",
    "        .toSeq:_*)\n",
    "\n",
    "prun_htoken_collectfreq.size\n",
    "\n",
    "timeit.uptonow / 60.0\n",
    "// 7.0919255263  , in minutes\n",
    "// 0.39257662956666667 , in minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "// time it\n",
    "timeit.start\n",
    "\n",
    "val prun_htoken_id: MutHashMap[Int, List[Int]] = \n",
    "    MutHashMap(\n",
    "        htoken_id.filterKeys(\n",
    "            pruned_token_set.contains(_)\n",
    "        ).toSeq:_*)\n",
    "\n",
    "prun_htoken_id.size\n",
    "\n",
    "timeit.uptonow / 60.0\n",
    "// 0.012546176999999999 , in minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// time it\n",
    "timeit.start\n",
    "\n",
    "val prun_id_htoken: MutHashMap[Int, List[Int]] = \n",
    "    MutHashMap(\n",
    "//         id_htoken.flatMap{ case (k,v) => (k, v.filter(pruned_token_set.contains(_))) }.\n",
    "        id_htoken.mapValues{ v => v.filter(pruned_token_set.contains(_)) }.\n",
    "        toSeq:_*)\n",
    "\n",
    "prun_id_htoken.size\n",
    "\n",
    "timeit.uptonow / 60.0\n",
    "// 0.20076514550000002 , in minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save pruned results to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_int_to_int(prun_htoken_collectfreq, PATH_prun_htoken_collectfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_int_to_intList(prun_htoken_id, PATH_prun_htoken_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_int_to_intList(prun_id_htoken, PATH_prun_id_htoken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load maps (pruned)\n",
    "## # start from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// time it\n",
    "timeit.start\n",
    "\n",
    "val prun_htoken_collectfreq: MutHashMap[Int, Int] = MutHashMap[Int, Int]()\n",
    "val prun_id_htoken: MutHashMap[Int, List[Int]] = MutHashMap[Int, List[Int]]()\n",
    "val prun_htoken_id: MutHashMap[Int, List[Int]] = MutHashMap[Int, List[Int]]()\n",
    "val id_name: MutHashMap[Int, String] = MutHashMap[Int, String]()\n",
    "val token_hash: MutHashMap[String, Int] = MutHashMap[String, Int]()\n",
    "val name_id: MutHashMap[String, Int] = MutHashMap[String, Int]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "load_mutmap_int_int(PATH_prun_htoken_collectfreq, prun_htoken_collectfreq)\n",
    "load_mutmap_int_intList(PATH_prun_id_htoken, prun_id_htoken)\n",
    "load_mutmap_int_intList(PATH_prun_htoken_id, prun_htoken_id)\n",
    "load_mutmap_int_string(PATH_id_name, id_name)\n",
    "load_mutmap_string_int(PATH_token_hash, token_hash)\n",
    "load_mutmap_string_int(PATH_name_id, name_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// time it\n",
    "timeit.uptonow / 60.0\n",
    "// 2.1530588158666664 , in minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_memory()\n",
    "\n",
    "// Used Memory:  2569\n",
    "// Free Memory:  1782\n",
    "// Total Memory: 4352\n",
    "// Max Memory:   5461"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queries & Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "// requires: having added tinyir to classpath, having added the qrels, i.e. \"relevance-judgements.csv\" in root \n",
    "// builds truth, an object, whose only method .judgements(\"query-ID\") returns the set of all document-IDs deemed \n",
    "// relevant to that query, note that these document-IDs are provided as List[String]\n",
    "// observe that query-ID is a string of an integer between 51 and 90 -> 40 queries in total\n",
    "import ch.ethz.dal.tinyir.lectures._\n",
    "val truth = new TipsterGroundTruth(files_path + \"/relevance-judgements.csv\")\n",
    "\n",
    "// how to use it, example:\n",
    "truth.judgements(\"51\")\n",
    "// observe that the size of relevant documents varies between queries, with the minimum being 52 and the maximum 894\n",
    "truth.judgements.values.map(x => x.size).min\n",
    "truth.judgements.values.map(x => x.size).max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// requires: having added the file \"questions-descriptions.txt\" to source\n",
    "// This cell will build a list (can be Stream if required) of query tokens. \n",
    "// Note that the 16 is hard-coded to ignore the first 15 characters of these <title> line, which all read \n",
    "// \"<title> Topic: \"\n",
    "import scala.io.Source\n",
    "val numPattern = \"[0-9]+\".r\n",
    "\n",
    "val title = Source.fromFile(files_path +\"questions-descriptions.txt\").getLines().filter(_.startsWith(\"<title>\"))\n",
    "                .map(_.substring(16).trim).map(x => token_filter(x)).toList\n",
    "\n",
    "val num = Source.fromFile(files_path +\"questions-descriptions.txt\").getLines().filter(_.startsWith(\"<num>\"))   \n",
    "                .map(x => numPattern.findFirstIn(x.toString).get.substring(1)).toList\n",
    "\n",
    "val query = num zip title\n",
    "query.sortBy(_._1) // the sorted order remains inherent to the object query (nice!!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Term-Frequency Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// DEFINE AUXILLARY FUNCTIONS\n",
    "\n",
    "// get inverse-document frequency (idf)\n",
    "// is defined as the logarithmically scaled inverse fraction of the documents that contain the word, \n",
    "// obtained by dividing the total number of documents by the number of documents containing the term, and then \n",
    "// taking the logarithm of that quotient.\n",
    "\n",
    "def hash_query(query: (String, List[String])) = {\n",
    "    (query._1, query._2.map(x => token_hash.getOrElse(x,-1)).filter(prun_htoken_id.keys.toSet.contains(_)).toSet)\n",
    "}\n",
    "\n",
    "val corpus_size = prun_id_htoken.size\n",
    "def get_idf(query: Set[Int]) = {\n",
    "    query.map(x => x -> Math.log(corpus_size / prun_htoken_id(x).size)).toMap\n",
    "}\n",
    "\n",
    "// get term frequency in a specific document (doc)\n",
    "def get_tf(query: Set[Int],doc: Int) = {\n",
    "    prun_id_htoken(doc).filter(query.contains(_)).groupBy(identity).mapValues(_.size)\n",
    "}\n",
    "\n",
    "// get tf-idf is defined as tf-idf = tf * idf\n",
    "def get_tf_idf(query: Set[Int],doc:Int) = {\n",
    "    get_tf(query,doc).map(x => x._1 -> x._2 * get_idf(query).getOrElse(x._1,0.toDouble))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// Handle a Query --> take in a query, produce a ranking\n",
    "def handle(query: (String, List[String])) = {\n",
    "    val hashed_query = hash_query(query)\n",
    "    val doc_set = hashed_query._2.map(x => prun_htoken_id(x)).flatten.toSet\n",
    "    val ranking = doc_set.map(x => x -> get_tf_idf(hashed_query._2,x).values.sum).toSeq.sortBy(-_._2)\n",
    "                    .take(100).map(x => x._1).toList    \n",
    "    (query._1,ranking)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// test it out.\n",
    "handle(query(35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "// Does it work on mass-answering queries?\n",
    "// It takes nearly 8 minutes though, so about 12 seconds per query on average. \n",
    "// Potential speed improvements: Write a function that reduces document collection in the first place.\n",
    "timeit.start\n",
    "val answers = query.map(x => handle(x)).toMap.mapValues(_.map(x => id_name(x)))\n",
    "timeit.uptonow / 60.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// The object Inspector contains all functions required to calculate the evaluation metrics (Precision, Recall, \n",
    "// F1-Score and MAP (mean average precision))\n",
    "\n",
    "object Inspector\n",
    "{\n",
    "// calculates average precision for a given answer (returned result of query)\n",
    "def badass1(retriev2: List[String], relev: Array[String], bounded: Boolean=false): Double ={\n",
    "    val retriev = retriev2.map(_.replace(\"-\", \"\"))\n",
    "    // remember to remove the \"-\" hyphens from the prediction for comparison purposes\n",
    "    (retriev.map(relev.contains(_)) // produces a boolean list with true where element belongs to relevant\n",
    "        .scanLeft(0){case (sum, next) => if(next) sum + 1 else sum}.tail // creates cumulative count of the booleans\n",
    "        .zipWithIndex.map(x => x._1.toDouble / (x._2 + 1)) // calculates average precision for each element\n",
    "        .zip(retriev.map(relev.contains(_))) // combines average precision with the boolean list from the start\n",
    "        .filter(_._2) // to filter out the ones that are not relevant \n",
    "        .map(_._1).sum // calculates the numerator (sums up the precision for all elements that are relevant)\n",
    "        )/ (if (bounded) retriev.size else relev.size) // divides by numerator (depending on bounded or not)\n",
    "    }\n",
    "\n",
    "// calculates mean average precision over a set of queries. \n",
    "def badass2(retriev_all: Map[String, List[String]], relev_all: Map[String, Array[String]], \n",
    "            bounded: Boolean=false): Double = {\n",
    "    (retriev_all.map(x => Inspector.badass1(x._2,relev_all(x._1),bounded)) // calculate average precision for each query\n",
    "    .sum)/(retriev_all.size) // calculates mean average precision (average precision over all queries)    \n",
    "}\n",
    "// Classic Precision and Recall for a given query, not striclty necessary. \n",
    "def evaluate(retriev: List[String], relev: Array[String])={\n",
    "    val TP = retriev.filter(relev.contains(_)).size.toDouble\n",
    "    val precision = TP / retriev.size\n",
    "    val recall = TP / relev.size\n",
    "    (precision,recall)\n",
    "}\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// Example Usage\n",
    "val query_ID = \"51\"\n",
    "Inspector.badass1(answers(query_ID),truth.judgements(query_ID),bounded=true)\n",
    "Inspector.badass2(answers,truth.judgements,bounded=true) // answers are my predictions, truth.judgements from tinyIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// investigate which queries cause problems.\n",
    "val query_ID = \"67\"\n",
    "truth.judgements(query_ID).size // How many relevant documents exist for that query?\n",
    "\n",
    "// Give a list of (AP, query_ID) for some easy investigation\n",
    "answers.map(x => Inspector.badass1(x._2,truth.judgements(x._1),bounded=true)).zip(answers.keys)//.filter(_._1<0.1)//.size\n",
    "\n",
    "// Look at a particular original query:\n",
    "query.toMap.get(query_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language model score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// maybe explicitly give higher score for doc id's\n",
    "// proportional to their frequency in the \"non distinct\" list\n",
    "test_single_query._2.flatMap(token => prun_htoken_id(token)).size\n",
    "test_single_query._2.flatMap(token => prun_htoken_id(token)).distinct.size\n",
    "\n",
    "// val doc_candidate = test_single_query._2.flatMap(token => prun_htoken_id(token)).distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Set((1,2), (2,3), (4,7)).map{ case (x,y) => x + y}\n",
    "List((1,2), (2,3), (4,7)).map{ case (x,y) => x + y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "val query_hash = query.map{ \n",
    "    case (id, str) => (id, str.\n",
    "                       flatMap(x => token_hash.get(x)).filter(pruned_token_set.contains(_))\n",
    "                      )}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "// // collection tf\n",
    "val collection_size = prun_htoken_collectfreq.foldLeft(0.0)(_+_._2)\n",
    "val collection_size_log = prun_htoken_collectfreq.foldLeft(0.0)(\n",
    "    (res,value) => res + Math.log(1.0 + value._2.toDouble))\n",
    "// val test_single_query = query_hash(1)\n",
    "// val candidates = candidate_doc(test_single_query)\n",
    "\n",
    "// handle scoring of 1 doc id\n",
    "val cur_id = candidates(0)\n",
    "// test_single_query._2\n",
    "\n",
    "val cur_doc_size = prun_id_htoken(cur_id).size\n",
    "\n",
    "val cur_doc_tf_map = prun_id_htoken(cur_id).\n",
    "        groupBy(identity).mapValues(_.size)\n",
    "\n",
    "// cur_doc_tf(29396)\n",
    "// cur_doc_tf(6268)\n",
    "\n",
    "val cur_doc_query_tf = test_single_query._2.map(token => \n",
    "                                                cur_doc_tf_map.getOrElse(token, 0).toDouble / cur_doc_size)\n",
    "\n",
    "// collection tf\n",
    "// can be executed once per query (not per query doc pair)\n",
    "// val collection_size = prun_htoken_collectfreq.foldLeft(0)(_+_._2)\n",
    "val cur_query_cf = test_single_query._2.map(token => \n",
    "                                            prun_htoken_collectfreq(token).toDouble / collection_size)\n",
    "\n",
    "val lambda = 0.01 // smoothing parameter\n",
    "\n",
    "val smooth_prob = cur_doc_query_tf.zip(cur_query_cf).map{case (x, y) => (1 - lambda) * x + lambda * y}\n",
    "\n",
    "// sum log(x) elements of list\n",
    "val cur_doc_lang_score = smooth_prob.foldLeft(0.0)(_ + Math.log(_))\n",
    "\n",
    "(cur_id, cur_doc_lang_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// collection tf\n",
    "val collection_size = prun_htoken_collectfreq.foldLeft(0)(_+_._2)\n",
    "\n",
    "val pruned_token_set = prun_htoken_collectfreq.keys.toSet\n",
    "\n",
    "val lambda = 0.01 // smoothing parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lang_query(query: (String, List[Int]),\n",
    "               method: String = \"index\", \n",
    "               log_opt: String = \"tf\",\n",
    "               prun_htoken_collectfreq: MutHashMap[Int, Int] = prun_htoken_collectfreq,\n",
    "               collection_size: Double = collection_size, \n",
    "               collection_size_log: Double = collection_size_log, \n",
    "               lambda: Double = lambda, \n",
    "               prun_id_htoken: MutHashMap[Int, List[Int]] = prun_id_htoken, \n",
    "               prun_htoken_id: MutHashMap[Int, List[Int]] = prun_htoken_id) = {\n",
    "    \n",
    "    // list of doc id's containing tokens in query\n",
    "    def candidate_doc(): List[Int] = method match {\n",
    "        case \"index\" => reduce_candidate_doc(query = query, take_k_results = take_k_results)\n",
    "        case \"no_index\" => (0 to 100000-1).toList\n",
    "//         case \"test\" => (1 to 2).toList\n",
    "        case _ => throw new Exception(\"Please choose either 'index' or 'no_index'\")\n",
    "//    def candidate_doc(): List[Int] = {\n",
    "// //        query._2.flatMap(token => prun_htoken_id(token)).distinct\n",
    "//        List(1,2,6,14,36,37,50,65,68)\n",
    "    }\n",
    "        \n",
    "    // map of tokens to frequency in a given doc\n",
    "    def doc_tf_map(doc_id: Int) = log_opt match {\n",
    "        case \"tf\" => prun_id_htoken(doc_id).\n",
    "            groupBy(identity).mapValues(x => x.size.toDouble)\n",
    "        case \"log\" => prun_id_htoken(doc_id).\n",
    "            groupBy(identity).mapValues(x => Math.log(1.0+x.size))\n",
    "        case _ => throw new Exception(\"Please choose either 'log' or 'tf'\")\n",
    "    }\n",
    "    \n",
    "    // number of tokens in doc\n",
    "    def doc_size(doc_id: Int) = {\n",
    "        doc_tf_map(doc_id).values.sum\n",
    "    }\n",
    "\n",
    "    // list of (relative) frequency of query tokens in a given doc\n",
    "    def doc_query_tf(doc_id: Int) = {\n",
    "        query._2.map(token => \n",
    "                     doc_tf_map(doc_id).getOrElse(token, 0.0) / doc_size(doc_id))\n",
    "    }\n",
    "    \n",
    "    // list of (relative) frequency of query tokens in the collection\n",
    "    def query_cf() = log_opt match {\n",
    "        case \"tf\" => query._2.map(token => \n",
    "                                  prun_htoken_collectfreq(token).toDouble / collection_size)\n",
    "        case \"log\" => query._2.map(token => \n",
    "                                  Math.log(1.0 + prun_htoken_collectfreq(token)) / collection_size_log)\n",
    "    }\n",
    "        \n",
    "    // this only needs to be calculated once per query\n",
    "    // (wasteful to call function multiple times)\n",
    "    val cur_query_cf = query_cf()\n",
    "    \n",
    "    //\n",
    "    def smooth_prob(doc_id: Int) = {\n",
    "        doc_query_tf(doc_id).zip(cur_query_cf).\n",
    "            map{case (x, y) => (1 - lambda) * x + lambda * y}\n",
    "    }\n",
    "    \n",
    "    // sum log(x) elements of list\n",
    "    def doc_lang_score(doc_id: Int) = {\n",
    "        smooth_prob(doc_id).foldLeft(0.0)(_ + Math.log(_))\n",
    "    }\n",
    "    \n",
    "    candidate_doc().map(doc => \n",
    "                        (query._1, doc, doc_lang_score(doc))\n",
    "                       ).sortWith(_._3 > _._3)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "// with raw log scores\n",
    "val lang_model_rank_time = query_hash.map(query => \n",
    "                       (query._1, unfold_name_time(\n",
    "                           lang_query(query, method = \"index\", log_opt = \"tf\"))\n",
    "                       )\n",
    "                                                 ).toMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "val lang_model_time = lang_model_rank_time.values.map(x => x._2)\n",
    "val lang_model_time_average = average(lang_model_time)\n",
    "\n",
    "// before reducing candidates\n",
    "// Iterable[Double] = List(\n",
    "//   0.3791437873666667,\n",
    "//   0.5371110624833333,\n",
    "//   9.883984977816668,\n",
    "//   1.4138989739999999,\n",
    "//   2.41249985935\n",
    "// )\n",
    "\n",
    "val lang_model_rank = lang_model_rank_time.mapValues(x => x._1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// Example Usage\n",
    "Inspector.badass2(lang_model_rank,truth.judgements,bounded=true) // answers are my predictions, truth.judgements from tinyIR\n",
    "\n",
    "// Inspector.evaluate(lang_model_rank(\"51\").map(_.replace(\"-\", \"\")),truth.judgements(\"51\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "// lang_model_rank.keys.toList.map(q_id => q_id)\n",
    "var precision = List[Double]()\n",
    "var recall = List[Double]()\n",
    "\n",
    "// (precision,recall)\n",
    "for (key <- lang_model_rank.keys) {\n",
    "//     println(key)\n",
    "    var p_r = Inspector.evaluate(lang_model_rank(key).map(_.replace(\"-\", \"\")),truth.judgements(key))\n",
    "    precision ++= List(p_r._1)\n",
    "    recall ++= List(p_r._2)\n",
    "}\n",
    "\n",
    "println(f\"mean precision is ${average(precision)}%1.3f\")\n",
    "// average(mean_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def lang_model_results_MAP(query_hash: List[(String, List[Int])] = query_hash, \n",
    "                           method: String, \n",
    "                           log_opt: String, \n",
    "                           lambda: Double = lambda, \n",
    "                           truth: TipsterGroundTruth = truth) = {\n",
    "    \n",
    "    val lang_model_rank_time = query_hash.map(query => \n",
    "                           (query._1, unfold_name_time(\n",
    "                               lang_query(query, \n",
    "                                          method = method, \n",
    "                                          log_opt = log_opt, \n",
    "                                          lambda = lambda))\n",
    "                           )\n",
    "                                             ).toMap\n",
    "    \n",
    "    val lang_model_time = average(lang_model_rank_time.values.map(x => x._2))\n",
    "    val lang_model_rank = lang_model_rank_time.mapValues(x => x._1)\n",
    "    println(f\"Average time per query is ${lang_model_time}%1.3f seconds\")\n",
    "    \n",
    "    val MAP_score = Inspector.badass2(lang_model_rank,truth.judgements,bounded=true)\n",
    "    println(f\"MAP score is ${MAP_score}%1.3f\")\n",
    "    \n",
    "    var precision = List[Double]()\n",
    "    \n",
    "    // (precision,recall)\n",
    "    for (key <- lang_model_rank.keys) {\n",
    "        var p_r = Inspector.evaluate(lang_model_rank(key).map(_.replace(\"-\", \"\")),truth.judgements(key))\n",
    "        precision ++= List(p_r._1)\n",
    "    //     recall ++= List(p_r._2)\n",
    "    }\n",
    "    println(f\"mean precision is ${average(precision)}%1.3f\")\n",
    "    \n",
    "    MAP_score\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lang_model_results_MAP(method = \"index\", \n",
    "                       log_opt = \"log\", \n",
    "                       lambda = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// Used Memory:  400\n",
    "// Free Memory:  215\n",
    "// Total Memory: 616\n",
    "// Max Memory:   3641"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val token_hm = MutHashMap[String, Int]()\n",
    "List(\"word1\", \"word3\").map(x => token_hm.getOrElseUpdate(x, token_hm.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classpath.addPath(tiny_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trait Result[T] extends Any {\n",
    "    def id : Int\n",
    "    def matches(that: T) : Int                 \n",
    "    def isMatch(that: T) = matches(that)==0\n",
    "    def matched(that: T) : T    \n",
    "}\n",
    "\n",
    "object InvertedIndex {\n",
    "    // generic list intersection (does not require sorted lists)\n",
    "    private def unsortedIntersect [A<% Result[A]](l1: List[A], l2: List[A]) = l1.intersect(l2)\n",
    "\n",
    "    // optimized list intersection for sorted posting lists \n",
    "    // uses \"matches\" and \"matched\" methods to work for all posting types\n",
    "    def sIntersect[A <% Result[A]] (l1: List[A], l2: List[A]) : List[A] = {\n",
    "        @annotation.tailrec\n",
    "        def iter (l1: List[A], l2: List[A], result: List[A]) : List[A] = {\n",
    "            if (l1.isEmpty || l2.isEmpty) \n",
    "                result.reverse\n",
    "            else (l1.head matches l2.head) match {\n",
    "                case n if n>0 => iter(l1, l2.tail,result)  // advance list l2\n",
    "                case n if n<0 => iter(l1.tail, l2,result)  // advance list l1\n",
    "                case _        => iter(l1.tail, l2.tail, (l1.head matched l2.head)::result)\t      \n",
    "            }\n",
    "        }    \n",
    "        iter(l1,l2,Nil)      \n",
    "    }\n",
    "}\n",
    "\n",
    "abstract class InvertedIndex[Res <% Result[Res]]  {\n",
    "    def results (term: String) : List[Res] \n",
    "    def results (terms: Seq[String]) : List[Res] = {\n",
    "        val resultLists      = terms.map(term => results(term))\n",
    "        val shortToLongLists = resultLists.sortWith( _.length < _.length) \n",
    "        shortToLongLists.reduceLeft( (l1,l2) => InvertedIndex.sIntersect(l1,l2) )\n",
    "    }\n",
    "}\n",
    "\n",
    "// import ch.ethz.dal.tinyir.indexing.InvertedIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scala.math._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Document(val id: Int, val tokens: List[Int])\n",
    "//     def id: Int = this.id\n",
    "//     def tokens: List[Int] = this.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "case class ProxResult(val id: Int, val lpos: Int, val rpos: Int) extends Result[ProxResult] {\n",
    "    def matches(that: ProxResult) : Int = {    \n",
    "        if (this.id != that.id) this.id - that.id\n",
    "        else if ((max(rpos,that.rpos) - min(lpos,that.lpos)) <= ProxWindow.size) 0 // match\n",
    "        else this.lpos-that.lpos  // advance in list with the minimal lpos\n",
    "    }\n",
    "    def matched(that: ProxResult) = \n",
    "        ProxResult(id, min(this.lpos,that.lpos), max(this.rpos,that.rpos))\n",
    "}\n",
    "\n",
    "object ProxWindow {\n",
    "    var size = 1\n",
    "    def setSize(w: Int) {assert(w>=1); size = w}\n",
    "}\n",
    "\n",
    "class PosIndex (docs: Stream[Document]) extends InvertedIndex[ProxResult] {\n",
    "\n",
    "    case class PosPosting(val id: Int, val pos: Int) extends Ordered[PosPosting] {\n",
    "        def this(t: PosTuple) = this(t.id, t.pos) \n",
    "//         def compare(that: PosPosting) = Ordering[Tuple2[Int, Int]].compare((this.id, this.pos), (that.id, that.pos) ) \n",
    "    }\n",
    "    type PostList = List[PosPosting]\n",
    "    val index : Map[String, PostList] = {\n",
    "        val groupedPostings = postings(docs).groupBy(_.term)\n",
    "        groupedPostings.mapValues(_.map(p => PosPosting(p.id,p.pos)).sorted)\n",
    "    }\n",
    "  \n",
    "    case class PosTuple(term: String, id: Int, pos: Int) \n",
    "    def postings (s: Stream[Document]): List[PosTuple] =\n",
    "        s.flatMap( d => d.tokens.zipWithIndex.map{ case (tk,pos) => PosTuple(tk,d.ID,pos) } ).toList\n",
    "\n",
    "    override def results (word: String) : List[ProxResult] = \n",
    "        index.getOrElse(word,null).map(p => ProxResult(p.id, p.pos, p.pos))\n",
    "    override def results (terms: Seq[String]) : List[ProxResult] = results(terms,1)\n",
    "    def results (terms: Seq[String], win: Int) : List[ProxResult] = {\n",
    "        val resultLists = terms.map(term => results(term))\n",
    "        val shortToLongLists = resultLists.sortWith( _.length < _.length)   \n",
    "        shortToLongLists.reduceLeft( (l1,l2) => InvertedIndex.sIntersect(l1,l2) )\n",
    "    } \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Scala 2.11",
   "language": "scala211",
   "name": "scala211"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
